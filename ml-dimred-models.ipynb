{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11109974,"sourceType":"datasetVersion","datasetId":6926501},{"sourceId":11175669,"sourceType":"datasetVersion","datasetId":6975037},{"sourceId":11175867,"sourceType":"datasetVersion","datasetId":6975190}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **pipeline2: pretrained cnn features**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision.models as models\nimport torchvision.transforms as transforms\n\n#method 1: pretrained cnn -- used for knn, logistic reg, svm, nn and ensemble method training\n# Load pre-trained ResNet model \nmodel = models.resnet18(pretrained=True)\nmodel = torch.nn.Sequential(*list(model.children())[:-1])  # Remove final classification layer\nmodel.eval()  # Set to evaluation mode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T10:53:52.010726Z","iopub.execute_input":"2025-05-23T10:53:52.011116Z","iopub.status.idle":"2025-05-23T10:54:03.371912Z","shell.execute_reply.started":"2025-05-23T10:53:52.011086Z","shell.execute_reply":"2025-05-23T10:54:03.370920Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Preprocessing**","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport cv2 as cv2\nimport os as os\nfrom sklearn.preprocessing import LabelEncoder\nimport torch\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n\n# Define folder paths for pleasant and unpleasant images\npleasant_path = \"/kaggle/input/mldata/train-images/train/pleasant\" \nunpleasant_path = \"/kaggle/input/mldata/train-images/train/unpleasant\" \ntest_path = \"/kaggle/input/mldata/TEST_images/TEST_images\"\n\n# List to store image data\nimage_data1 = []\nimage_data2 = []\n\ntest_data = []\n\n# Process Pleasant Images\nfor filename in sorted(os.listdir(pleasant_path)):\n    if filename.endswith(\".jpg\"):\n        image_data1.append([filename, 1])\n\n# Process Unpleasant Images\nfor filename in sorted(os.listdir(unpleasant_path)):\n    if filename.endswith(\".jpg\"):\n        image_data2.append([filename, 0])\n\n# Process test images\nfor filename in sorted(os.listdir(test_path)):\n    if filename.endswith(\".jpg\"):\n        test_data.append([filename, 0]) #defaults to unpleasant label (0)\n\n# Create DataFrame\ndf1 = pd.DataFrame(image_data1, columns=[\"Filename\", \"Label\"])\ndf2 = pd.DataFrame(image_data2, columns=[\"Filename\", \"Label\"])\ndf3 = pd.DataFrame(test_data, columns=[\"Filename\", \"Label\"])\n\n#df1.head()\n#df2.head()\n\n# show info for all files (count,freq,unique)\nprint(df1.describe())\nprint(df2.describe())\n\n# Save to CSV\ndf1.to_csv(\"pleasant_labels.csv\", index=False)\ndf2.to_csv(\"unpleasant_labels.csv\", index=False)\n\n# Image transformations (match what ResNet expects)\ntransform = transforms.Compose([\n    transforms.Resize((128, 128)),  # Resize image\n    transforms.ToTensor(),  # Convert to tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n])\n\n\nlabels_df = pd.concat([df1, df2], ignore_index=True)\nlabels_df.to_csv(\"test.csv\",index=False)\n\nimage_features = []\nlabels = []\npleasant = pleasant_path\nprint(pleasant)\nunpleasant = unpleasant_path\nprint(unpleasant)\n\n#(1)\n# Process each image and get its assigned label\nfor _, row in labels_df.iterrows():\n    \n    label = row[\"Label\"]\n    filename = os.path.basename(row[\"Filename\"])\n\n    if(label == 1):\n        img_path = pleasant+\"/\"+filename\n    elif(label == 0):\n        img_path = unpleasant+\"/\"+filename\n    \n    # Load and preprocess image\n    img = Image.open(img_path).convert(\"RGB\")\n    img = transform(img).unsqueeze(0)  \n\n        # Extract features\n    with torch.no_grad():\n        features = model(img)\n\n    features = features.view(-1).numpy()  # Flatten feature vector\n\n        # Store features & label\n    image_features.append(features)\n    labels.append(label)\n\n# Convert to DataFrame\n\ndf = pd.DataFrame(image_features)\ndf[\"Label\"] = labels # labels are the targets\ndf = df.dropna()\n# Save features to CSV\ndf.to_csv(\"extracted_features_pytorch.csv\", index=False)\n\n# Display first few rows\ndf.head()\nprint(df.describe())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T10:54:03.374255Z","iopub.execute_input":"2025-05-23T10:54:03.374911Z","iopub.status.idle":"2025-05-23T10:57:04.432267Z","shell.execute_reply.started":"2025-05-23T10:54:03.374876Z","shell.execute_reply":"2025-05-23T10:57:04.431348Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df1.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T10:57:04.433463Z","iopub.execute_input":"2025-05-23T10:57:04.433811Z","iopub.status.idle":"2025-05-23T10:57:04.453722Z","shell.execute_reply.started":"2025-05-23T10:57:04.433777Z","shell.execute_reply":"2025-05-23T10:57:04.452738Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_features2 = []\nlabels2 = []\n\n# Image transformations (match what ResNet expects)\ntransform = transforms.Compose([\n    transforms.Resize((128, 128)),  # Resize image\n    transforms.ToTensor(),  # Convert to tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n])\n\n\ndf3.to_csv(\"test2.csv\",index=False)\n#(1)\n# Process each image and get its assigned label\nfor _, row in df3.iterrows():\n    \n    label = row[\"Label\"]\n    filename = os.path.basename(row[\"Filename\"])\n\n    img_path = test_path+\"/\"+filename\n  \n\n    if img_path is None: #testing\n         print(f\"Warning: {filename} not found in any folder!\")\n         continue\n\n    # print(f\"Processing: {img_path} with label {label}\") #debugging\n    \n    # Load and preprocess image\n    img = Image.open(img_path).convert(\"RGB\")\n    img = transform(img).unsqueeze(0)  # Add batch dimension\n\n    # Extract features\n    with torch.no_grad():\n        features = model(img)\n\n    features = features.view(-1).numpy()  # Flatten feature vector\n\n    # Store features & label\n    image_features2.append(features)\n    labels2.append(label)\n\n# Convert to DataFrame\ndft = pd.DataFrame(image_features2)\ndft[\"Label\"] = labels2 # so basically labels are the targets\ndft = dft.dropna()\n# Save features to CSV\ndft.to_csv(\"extracted_features_test.csv\", index=False)\n\n# Display first few rows\ndft.head()\nprint(dft.describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T10:57:04.454705Z","iopub.execute_input":"2025-05-23T10:57:04.454989Z","iopub.status.idle":"2025-05-23T10:57:22.320385Z","shell.execute_reply.started":"2025-05-23T10:57:04.454967Z","shell.execute_reply":"2025-05-23T10:57:22.319381Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **train-test set split**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n# Split features (X) and labels (y)\nX = df.iloc[:, :-1]  # Features after preprocessing\ny = df.iloc[:, -1]  # Corresponding labels\n\n# Train-test split (80% train, 20% test)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nl = LabelEncoder()\ny_train_enc = l.fit_transform(y_train)\ny_test_enc = l.fit_transform(y_test)\ni =0\nwhile(i<5):\n    print(y_train_enc[i]) #head() but for this particular array\n    i+=1\n\nX_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T10:57:22.321533Z","iopub.execute_input":"2025-05-23T10:57:22.321895Z","iopub.status.idle":"2025-05-23T10:57:22.493608Z","shell.execute_reply.started":"2025-05-23T10:57:22.321845Z","shell.execute_reply":"2025-05-23T10:57:22.492664Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **dimension reduction**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import LocallyLinearEmbedding\n\ndef plot_2d(X_2d, y=None):\n    X_2d = np.array(X_2d)\n    if y is not None:\n        y = np.array(y)\n    plt.figure(figsize=(8, 6))\n    scatter = plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', 2), alpha=0.7)\n    plt.colorbar(scatter, ticks=[0, 1], label='Class')\n    plt.xlabel('Dim 1')\n    plt.ylabel('Dim 2')\n    plt.title('2D Visualization')\n    plt.grid(True)\n    plt.show()\n\ndef plot_3d(X_3d, y=None):\n    X_3d = np.array(X_3d)\n    if y is not None:\n        y = np.array(y)\n    fig = plt.figure(figsize=(10, 8))\n    ax = fig.add_subplot(111, projection='3d')\n    scatter = ax.scatter(X_3d[:, 0], X_3d[:, 1], X_3d[:, 2], c=y, cmap='viridis', alpha=0.7)\n    ax.set_xlabel('Dim 1')\n    ax.set_ylabel('Dim 2')\n    ax.set_zlabel('Dim 3')\n    ax.set_title('3D Visualization')\n    fig.colorbar(scatter, label='Class')\n    plt.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T10:57:22.494781Z","iopub.execute_input":"2025-05-23T10:57:22.495188Z","iopub.status.idle":"2025-05-23T10:57:22.871642Z","shell.execute_reply.started":"2025-05-23T10:57:22.495159Z","shell.execute_reply":"2025-05-23T10:57:22.870622Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import LocallyLinearEmbedding\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense\nfrom tensorflow.keras.optimizers import Adam\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n\ndef build_autoencoder(input_dim, latent_dim):\n    input_layer = Input(shape=(input_dim,))\n    \n    # Encoder with 2 hidden layers\n    encoded = Dense(128, activation='relu')(input_layer)\n    encoded = Dense(256, activation='relu')(encoded)\n    latent = Dense(latent_dim)(encoded)\n    \n    # Decoder with 2 hidden layers (reverse order)\n    decoded = Dense(256, activation='relu')(latent)\n    decoded = Dense(128, activation='relu')(decoded)\n    output_layer = Dense(input_dim)(decoded)\n\n    autoencoder = Model(input_layer, output_layer)\n    encoder = Model(input_layer, latent)\n\n    autoencoder.compile(optimizer=Adam(1e-3), loss='mse')\n    return autoencoder, encoder\n\ndef dim_reduct(model,m, X_train, X_test):\n    # Ensure numpy arrays\n    X_train = np.array(X_train)\n    X_test = np.array(X_test)\n\n    \n    if model == \"pca\":\n            pca = PCA(n_components=m)\n            X_train_d = pca.fit_transform(X_train)\n            X_test_d = pca.transform(X_test)\n            if m == 2:\n                plot_2d(X_train_d,y_train.values)\n            elif m == 3:\n                plot_3d(X_train_d,y_train.values)\n            return X_train_d\n\n    elif model == \"lle\":\n            lle = LocallyLinearEmbedding(n_components=m, n_neighbors=10)\n            X_train_d = lle.fit_transform(X_train)\n            if m == 2:\n                plot_2d(X_train_d,y_train.values)\n            elif m == 3:\n                plot_3d(X_train_d,y_train.values)\n            return X_train_d\n\n    elif model == \"autoenc\":\n            input_dim = X_train.shape[1]\n\n            # Build autoencoder for given latent size\n            autoencoder, encoder = build_autoencoder(input_dim, latent_dim=m)\n\n            # Train the autoencoder\n            autoencoder.fit(X_train, X_train, epochs=20, batch_size=64, shuffle=True, verbose=0)\n\n            # Transform (encode) the data\n            X_train_d = encoder.predict(X_train)\n\n            # Plot\n            if m == 2:\n                plot_2d(X_train_d,y_train.values)\n            elif m == 3:\n            # Build and compile 3D autoencoder\n                autoencoder_3d, encoder_3d = build_autoencoder(input_dim, latent_dim=3)\n                autoencoder_3d.compile(optimizer=Adam(1e-3), loss='mse') \n                autoencoder_3d.fit(X_train, X_train, epochs=20, batch_size=64, shuffle=True, verbose=0)\n\n                X_train_3d = encoder_3d.predict(X_train)\n                plot_3d(X_train_3d, y_train.values)\n            return X_train_d\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T10:57:22.873118Z","iopub.execute_input":"2025-05-23T10:57:22.873445Z","iopub.status.idle":"2025-05-23T10:57:40.794325Z","shell.execute_reply.started":"2025-05-23T10:57:22.873415Z","shell.execute_reply":"2025-05-23T10:57:40.793305Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **evaluation method**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import RocCurveDisplay, ConfusionMatrixDisplay\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import silhouette_score\nfrom collections import Counter\nfrom scipy.stats import mode\n\ndef purity_score_labels(y_true, y_pred):\n\n    clusters = np.unique(y_pred) # unique values of prediction\n    total = len(y_true) # counts unique values\n    correct = 0\n    for cluster in clusters:\n        idx = (y_pred == cluster)\n        true_labels = y_true[idx]\n        if len(true_labels) == 0:\n            continue\n        most_common, count = mode(true_labels, keepdims=True)\n        correct += count[0]\n    return correct / total\n\n\ndef compute_metrics_labels(X, y_true, y_pred):\n    # Classification report\n    print(classification_report(y_true, y_pred))\n\n    # Silhouette score\n    sil_score = silhouette_score(X, y_pred)\n    print(f\"Silhouette Score: {sil_score:.4f}\")\n\n    # Purity score\n    purity = purity_score_labels(np.array(y_true), np.array(y_pred))\n    print(f\"Purity: {purity:.4f}\")\n\n    # F1 Score\n    f1 = f1_score(y_true, y_pred, average='macro')\n    print(f\"F1 Score: {f1:.4f}\")\n\n    # Confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    print(\"Confusion Matrix:\\n\", cm)\n\n    return sil_score, purity, f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T10:57:40.797277Z","iopub.execute_input":"2025-05-23T10:57:40.797812Z","iopub.status.idle":"2025-05-23T10:57:40.806544Z","shell.execute_reply.started":"2025-05-23T10:57:40.797788Z","shell.execute_reply":"2025-05-23T10:57:40.805657Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **model training**","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import KMeans, AgglomerativeClustering\nfrom sklearn.metrics import pairwise_distances\nfrom sklearn.base import clone\n\nM = [2,3,5,10,15,20]\nK = [2,3,4,5,6,7,8,9,10]\ndim_models = [\"pca\",\"lle\",\"autoenc\"]\nclust_models = [\"kmeucl\",\"kmcos\",\"agglo\"]\nsil_score = 0\npurity = 0\nf1 = 0\n\ndef clustering_pipeline(X,y,k,model):\n    # Euclidean KMeans\n    if(model == \"kmeucl\"):\n        kmeans_eucl = KMeans(n_clusters=k, random_state=42)\n        y_pred_eucl = kmeans_eucl.fit_predict(X)\n        sil_score, purity, f1 = compute_metrics_labels(X, y, y_pred_eucl)\n    elif(model == \"kmcos\"):\n        cosine_dist = pairwise_distances(X, metric='cosine')\n        kmeans_cos = KMeans(n_clusters=len(np.unique(y)), random_state=42)\n        y_pred_cos = kmeans_cos.fit_predict(cosine_dist)\n        sil_score, purity, f1 = compute_metrics_labels(X, y, y_pred_cos)\n    elif(model == \"agglo\"):\n        agglo = AgglomerativeClustering(n_clusters=len(np.unique(y)))\n        y_pred_agglo = agglo.fit_predict(X)\n        sil_score, purity, f1 = compute_metrics_labels(X, y, y_pred_agglo)\n    return {\"silhouette\": sil_score, \n            \"purity\": purity, \n            \"f1\": f1, \n            \"k\":k,\n            \"model\": model}\n\nresults = []\nbest_score = -1\nbest_model = None\nbest_params = {}\nbest_k = -1\n    \nfor m in M:\n    print(\"---------------------------\",m,\"---------------------------\")\n    for model in dim_models:\n        print(\"=======================\",model,\"=======================\")\n        for k in K:\n            for cmodel in clust_models:\n                X_train_red = dim_reduct(model,m,X_train,X_test)\n                #clustering_pipeline(X_train_red, y_train,k,cmodel)\n                res = clustering_pipeline(X_train_red, y_train, k, cmodel)\n                res.update({\"dim_red_model\": model, \"m\": m})\n                results.append(res)\n                \n                # Update best\n                if res[\"silhouette\"] > best_score:\n                    best_score = res[\"silhouette\"]\n                    best_model = res\n                    best_k = k\n                  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T10:57:40.807365Z","iopub.execute_input":"2025-05-23T10:57:40.807607Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"M = [15,20] #repeated procedure run due to technical problems on kaggle environment\nfor m in M:\n    print(\"---------------------------\",m,\"---------------------------\")\n    for model in dim_models:\n        print(\"=======================\",model,\"=======================\")\n        for k in K:\n            for cmodel in clust_models:\n                X_train_red = dim_reduct(model,m,X_train,X_test)\n                #clustering_pipeline(X_train_red, y_train,k,cmodel)\n                res = clustering_pipeline(X_train_red, y_train, k, cmodel)\n                res.update({\"dim_red_model\": model, \"m\": m})\n                results.append(res)\n                \n                # Update best\n                if res[\"silhouette\"] > best_score:\n                    best_score = res[\"silhouette\"]\n                    best_model = res\n                    best_k = k","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:30:48.236558Z","iopub.execute_input":"2025-05-23T12:30:48.236923Z","iopub.status.idle":"2025-05-23T13:00:38.613086Z","shell.execute_reply.started":"2025-05-23T12:30:48.236898Z","shell.execute_reply":"2025-05-23T13:00:38.611798Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Best configuration based on Silhouette Score:\")\nprint(best_model)\nprint(\"Best k* based on Silhouette Score:\")\nprint(best_k)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T13:01:38.477766Z","iopub.execute_input":"2025-05-23T13:01:38.478742Z","iopub.status.idle":"2025-05-23T13:01:38.483843Z","shell.execute_reply.started":"2025-05-23T13:01:38.478703Z","shell.execute_reply":"2025-05-23T13:01:38.482881Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport pandas as pd\nresults_df = pd.DataFrame(results)\nresults_df.to_csv(\"clustering_sil_results.csv\",index=False)\n\nfor model in dim_models:\n    for cmodel in clust_models:\n        subset = results_df[(results_df[\"dim_red_model\"] == model) & (results_df[\"model\"] == cmodel)]\n        plt.figure()\n        sns.lineplot(data=subset, x=\"k\", y=\"silhouette\", hue=\"m\", marker=\"o\")\n        plt.title(f\"{model} + {cmodel} - Silhouette vs k\")\n        plt.xlabel(\"Number of Clusters (k)\")\n        plt.ylabel(\"Silhouette Score\")\n        plt.legend(title=\"Dim m\")\n        plt.grid(True)\n        plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T13:01:43.891361Z","iopub.execute_input":"2025-05-23T13:01:43.891734Z","iopub.status.idle":"2025-05-23T13:01:49.266561Z","shell.execute_reply.started":"2025-05-23T13:01:43.891680Z","shell.execute_reply":"2025-05-23T13:01:49.265555Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef plot_scores_vs_k(results_df, model_filter, dim_method_filter):\n    df = results_df[(results_df['model'] == model_filter) & \n                    (results_df['dim_red_model'] == dim_method_filter)]\n\n    plt.figure(figsize=(10, 6))\n    sns.lineplot(x='k', y='silhouette', data=df, label='Silhouette Score', marker='o')\n    sns.lineplot(x='k', y='purity', data=df, label='Purity', marker='s')\n    plt.title(f'Scores vs k for {model_filter} + {dim_method_filter}')\n    plt.xlabel('Number of Clusters (k)')\n    plt.ylabel('Score')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n    \nfor model in dim_models:\n    for cmodel in clust_models:\n        plot_scores_vs_k(results_df,cmodel,model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T13:02:08.685963Z","iopub.execute_input":"2025-05-23T13:02:08.686267Z","iopub.status.idle":"2025-05-23T13:02:13.995883Z","shell.execute_reply.started":"2025-05-23T13:02:08.686247Z","shell.execute_reply":"2025-05-23T13:02:13.994774Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pivoted = results_df.pivot_table(index='k', columns='model', values='silhouette')\nsns.heatmap(pivoted, annot=True, cmap=\"viridis\")\nplt.title('Silhouette Scores by Clustering Model and k')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T13:02:36.626802Z","iopub.execute_input":"2025-05-23T13:02:36.627226Z","iopub.status.idle":"2025-05-23T13:02:36.997041Z","shell.execute_reply.started":"2025-05-23T13:02:36.627197Z","shell.execute_reply":"2025-05-23T13:02:36.996001Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_k_df = results_df.loc[results_df.groupby(['model', 'dim_red_model'])['silhouette'].idxmax()]\nsns.barplot(x='dim_red_model', y='k', hue='model', data=best_k_df)\nplt.title('Best k per Clustering + Dim. Reduction Method')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T13:02:56.491188Z","iopub.execute_input":"2025-05-23T13:02:56.491590Z","iopub.status.idle":"2025-05-23T13:02:56.767872Z","shell.execute_reply.started":"2025-05-23T13:02:56.491566Z","shell.execute_reply":"2025-05-23T13:02:56.766759Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\nresults_df = pd.DataFrame(results)\n\nsummary_df = results_df.pivot_table(\n    index=['dim_red_model', 'model', 'k'],\n    values=['silhouette', 'purity', 'f1']\n).reset_index()\n\n# Sort by silhouette\nsummary_df = summary_df.sort_values(by='silhouette', ascending=False)\nsummary_df.to_csv(\"clustering_summary.csv\", index=False)\n\n# Show top results\nprint(summary_df.head(10))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T13:03:18.624819Z","iopub.execute_input":"2025-05-23T13:03:18.625137Z","iopub.status.idle":"2025-05-23T13:03:18.646618Z","shell.execute_reply.started":"2025-05-23T13:03:18.625118Z","shell.execute_reply":"2025-05-23T13:03:18.645497Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **pipeline2 final training**","metadata":{}},{"cell_type":"code","source":"import csv\n\nX_unknown = dft.iloc[:, :-1] #aligned with df3a\n\ny_pred_u = best_model2.predict(X_unknown)\n\n\nunknown_pics = pd.read_csv('/kaggle/input/mldata/Test-IDs.csv')\nsize = y_pred_u.size\n\npics_unordered = df3[\"Filename\"].tolist()\npics_ordered = unknown_pics[\"Filename\"].tolist()\n\nunordered_map = {filename: index for index, filename in enumerate(pics_unordered)}\n\n# Initialize the sorted_labels array with zero values.\nsorted_labels = [0] * size\n\n# for filename in pics_ordered:\n#     if filename not in unordered_map:\n#         print(f\"Filename '{filename}' not found in unordered_map!\")\n\n# Step 1: Normalize both lists (strip whitespace and lowercase everything)\npics_unordered_norm = [p.strip().lower() for p in df3[\"Filename\"].tolist()]\npics_ordered_norm = [p.strip().lower() for p in unknown_pics[\"Filename\"].tolist()]\n\n# # Step 2: Get missing filenames\n# missing_files = [f for f in pics_ordered_norm if f not in pics_unordered_norm]\n\n# print(f\"Missing: {len(missing_files)} out of {len(pics_ordered_norm)} filenames.\")\n# print(\"Example missing filenames:\", missing_files[:10])\n\n\n# Loop over each entry in pics_ordered and assign the corresponding y_pred_u value to the sorted_labels.\nfor idx, filename in enumerate(pics_ordered):\n\n    unordered_index = unordered_map[filename]\n    \n    sorted_labels[unordered_index] = y_pred_u[idx]\n\nfor i in range(size):\n    if sorted_labels[i] == 0:\n        sorted_labels[i] = \"0\"\nid_list = [i for i in range(size)]\n\nwith open('output_labels.csv', mode='w', newline='') as file:\n    writer = csv.writer(file, delimiter=',')  # delimiter is a comma\n    \n    writer.writerow(['ID', 'label'])\n    \n    for i in range(len(id_list)):\n        writer.writerow([id_list[i], str(sorted_labels[i])])  # Convert to string\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}